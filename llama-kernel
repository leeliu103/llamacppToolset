#!/usr/bin/env python3

import argparse
import hashlib
import json
import os
import re
import shlex
import shutil
import subprocess
import sys
import time
from pathlib import Path
import tomllib


CONFIG_BASENAME = "llama-kernel.toml"
SUPPORTED_KERNELS = {"mmvq": "ggml/src/ggml-cuda/mmvq.cu"}


class ToolError(RuntimeError):
    pass


def eprint(*args, **kwargs):
    print(*args, file=sys.stderr, **kwargs)


def load_config() -> dict:
    config_path = os.environ.get("LLAMA_KERNEL_CONFIG")
    candidates = []
    if config_path:
        candidates.append(Path(config_path))
    candidates.append(Path.cwd() / CONFIG_BASENAME)
    candidates.append(Path(__file__).resolve().parent / CONFIG_BASENAME)

    for path in candidates:
        if path.exists():
            with path.open("rb") as f:
                data = tomllib.load(f)
            data["_config_path"] = str(path)
            return data

    raise ToolError(
        "Config not found. Set LLAMA_KERNEL_CONFIG or place llama-kernel.toml in the current directory or next to the script."
    )


def resolve_paths(cfg: dict) -> dict:
    llamacpp = Path(cfg.get("llamacpp", "")).expanduser()
    out_base = Path(cfg.get("out", "")).expanduser()
    kernel = cfg.get("kernel", "")
    build_dir = cfg.get("build_dir")

    if not llamacpp:
        raise ToolError("Config missing 'llamacpp'.")
    if not out_base:
        raise ToolError("Config missing 'out'.")
    if not kernel:
        raise ToolError("Config missing 'kernel'.")
    if kernel not in SUPPORTED_KERNELS:
        raise ToolError(f"Unsupported kernel '{kernel}'. Supported: {', '.join(SUPPORTED_KERNELS)}")

    cfg["llamacpp"] = llamacpp
    cfg["out"] = out_base
    cfg["kernel"] = kernel
    cfg["build_dir"] = Path(build_dir).expanduser() if build_dir else None
    return cfg


def find_compile_commands(llamacpp: Path, build_dir: Path | None) -> Path:
    if build_dir:
        if build_dir.is_file() and build_dir.name == "compile_commands.json":
            return build_dir
        cc = build_dir / "compile_commands.json"
        if cc.exists():
            return cc
        raise ToolError(f"compile_commands.json not found under build_dir: {build_dir}")

    preferred = llamacpp / "build" / "compile_commands.json"
    if preferred.exists():
        return preferred

    candidates = list(llamacpp.rglob("compile_commands.json"))
    if len(candidates) == 1:
        return candidates[0]
    if not candidates:
        raise ToolError("No compile_commands.json found. Reconfigure CMake with -DCMAKE_EXPORT_COMPILE_COMMANDS=ON.")

    msg = "Multiple compile_commands.json found. Set build_dir in config.\n"
    for c in candidates:
        msg += f"  - {c}\n"
    raise ToolError(msg.rstrip())


def build_root_from_cc(cc_path: Path, cfg: dict) -> Path:
    build_dir = cfg.get("build_dir")
    if build_dir:
        if isinstance(build_dir, Path):
            bd = build_dir
        else:
            bd = Path(build_dir)
        return bd.parent if bd.is_file() else bd
    return cc_path.parent


def load_compile_command(cc_path: Path, tu_rel: str) -> dict:
    with cc_path.open("r", encoding="utf-8") as f:
        data = json.load(f)

    for entry in data:
        file_path = entry.get("file", "")
        if file_path.replace("\\", "/").endswith(tu_rel):
            return entry

    raise ToolError(f"No compile command found for {tu_rel} in {cc_path}")


def clang_tools_from_command(cmd: list[str]) -> dict:
    clang = cmd[0]
    clang_path = Path(clang)
    tool_dir = clang_path.parent if clang_path.exists() else None

    def tool(name: str) -> str:
        if tool_dir:
            candidate = tool_dir / name
            if candidate.exists():
                return str(candidate)
        found = shutil.which(name)
        if found:
            return found
        raise ToolError(f"Required tool '{name}' not found.")

    return {
        "clang": clang,
        "llvm_dis": tool("llvm-dis"),
        "llvm_objcopy": tool("llvm-objcopy"),
        "llvm_readobj": tool("llvm-readobj"),
        "llvm_mc": tool("llvm-mc"),
        "ld_lld": tool("ld.lld"),
        "clang_offload_bundler": tool("clang-offload-bundler"),
    }


def build_command(entry: dict, out_obj: Path, extra_flags: list[str]) -> tuple[list[str], Path]:
    cmd = shlex.split(entry["command"])
    workdir = Path(entry["directory"])

    # Replace -o output
    if "-o" in cmd:
        i = cmd.index("-o")
        cmd[i + 1] = str(out_obj)
    else:
        cmd += ["-o", str(out_obj)]

    # Remove existing save-temps flags to avoid duplicates
    cmd = [c for c in cmd if not c.startswith("--save-temps")]

    cmd += extra_flags
    return cmd, workdir


def parse_offload_arch(cmd: list[str]) -> str:
    # Prefer explicit --offload-arch flags
    for i, arg in enumerate(cmd):
        if arg.startswith("--offload-arch="):
            return arg.split("=", 1)[1]
        if arg == "--offload-arch" and i + 1 < len(cmd):
            return cmd[i + 1]
        if arg.startswith("-foffload-arch="):
            return arg.split("=", 1)[1]
        if arg == "-foffload-arch" and i + 1 < len(cmd):
            return cmd[i + 1]
    raise ToolError("Missing --offload-arch in compile command. Rebuild with GPU target specified.")


def find_output_object(entry: dict, cc_path: Path) -> Path:
    if "output" in entry and entry["output"]:
        out = Path(entry["output"])
    else:
        cmd = shlex.split(entry["command"])
        if "-o" not in cmd:
            raise ToolError("Cannot find output object path in compile command.")
        out = Path(cmd[cmd.index("-o") + 1])
    if not out.is_absolute():
        out = Path(entry["directory"]) / out
    out = out.resolve()
    if out.exists():
        return out

    # Fallback: search for mmvq.cu.o under the build root (parent of compile_commands.json)
    build_root = cc_path.parent
    candidates = list(build_root.rglob("mmvq.cu.o"))
    if not candidates:
        raise ToolError(f"Output object not found: {out}")
    candidates.sort(key=lambda p: p.stat().st_mtime, reverse=True)
    return candidates[0].resolve()


def pick_latest_dir(base: Path) -> Path | None:
    if not base.exists():
        return None
    return base


def safe_name(name: str) -> str:
    cleaned = re.sub(r"[^A-Za-z0-9_.-]", "_", name)
    if len(cleaned) <= 80:
        return cleaned
    h = hashlib.sha1(name.encode("utf-8")).hexdigest()[:8]
    return f"{cleaned[:72]}_{h}"


def find_device_artifacts(out_dir: Path) -> tuple[Path, Path]:
    device_s = list(out_dir.glob("*amdgcn-amd-amdhsa*.s"))
    device_bc = list(out_dir.glob("*amdgcn-amd-amdhsa*.bc"))

    if not device_s:
        raise ToolError("Device .s not found in output directory.")
    if not device_bc:
        raise ToolError("Device .bc not found in output directory.")

    device_s.sort(key=lambda p: p.stat().st_mtime, reverse=True)
    device_bc.sort(key=lambda p: p.stat().st_mtime, reverse=True)
    return device_s[0], device_bc[0]


def find_device_out(out_dir: Path) -> Path | None:
    device_out = list(out_dir.glob("*amdgcn-amd-amdhsa*.out"))
    if not device_out:
        return None
    device_out.sort(key=lambda p: p.stat().st_mtime, reverse=True)
    return device_out[0]


def generate_mangled_map(llvm_dis: str, bc_path: Path, out_map: Path) -> int:
    proc = subprocess.run([llvm_dis, str(bc_path), "-o", "-"],
                          stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
    if proc.returncode != 0:
        eprint(proc.stderr)
        raise ToolError("llvm-dis failed.")

    mangled = []
    seen = set()
    for line in proc.stdout.splitlines():
        if "define " in line and "@" in line:
            start = line.find("@") + 1
            end = line.find("(", start)
            if end == -1:
                continue
            sym = line[start:end].strip()
            if sym and sym not in seen:
                seen.add(sym)
                mangled.append(sym)

    proc_dem = subprocess.run(["c++filt"], input="\n".join(mangled) + "\n",
                              text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    if proc_dem.returncode != 0:
        eprint(proc_dem.stderr)
        raise ToolError("c++filt failed.")

    demangled = proc_dem.stdout.splitlines()
    with out_map.open("w", encoding="utf-8") as f:
        for m, d in zip(mangled, demangled):
            f.write(f"{m}\t{d}\n")

    return len(mangled)


def clean_dir(path: Path, keep_files: set[str], keep_dirs: set[str] | None = None):
    keep_dirs = keep_dirs or set()
    for child in path.iterdir():
        if child.is_dir():
            if child.name in keep_dirs:
                continue
            shutil.rmtree(child)
            continue
        if child.name in keep_files:
            continue
        child.unlink()


def run_dump(cfg: dict) -> Path:
    kernel = cfg["kernel"]
    tu_rel = SUPPORTED_KERNELS[kernel]
    llamacpp = cfg["llamacpp"]
    out_base = cfg["out"]

    cc_path = find_compile_commands(llamacpp, cfg.get("build_dir"))
    entry = load_compile_command(cc_path, tu_rel)
    cmd_tools = clang_tools_from_command(shlex.split(entry["command"]))

    kernel_dir = out_base / kernel
    if kernel_dir.exists():
        shutil.rmtree(kernel_dir)
    kernel_dir.mkdir(parents=True, exist_ok=True)
    dump_dir = kernel_dir

    out_obj = dump_dir / "mmvq.cu.o"
    extra = ["--save-temps=obj"]
    cmd, workdir = build_command(entry, out_obj, extra)

    eprint(f"[dump] compile from {cc_path}")
    eprint(f"[dump] output: {dump_dir}")

    proc = subprocess.run(cmd, cwd=workdir)
    if proc.returncode != 0:
        raise ToolError("Compilation failed during dump.")

    device_s, device_bc = find_device_artifacts(dump_dir)
    shutil.copy2(device_s, dump_dir / "amdgcn.s")
    shutil.copy2(device_bc, dump_dir / "device.bc")

    map_path = dump_dir / "mangled_map.tsv"
    count = generate_mangled_map(cmd_tools["llvm_dis"], dump_dir / "device.bc", map_path)

    clean_dir(dump_dir, keep_files={"amdgcn.s", "device.bc", "mangled_map.tsv"}, keep_dirs={"llvmir"})
    eprint(f"[dump] symbols mapped: {count}")
    return dump_dir


def load_map(map_path: Path) -> list[tuple[str, str]]:
    items = []
    with map_path.open("r", encoding="utf-8") as f:
        for line in f:
            line = line.rstrip("\n")
            if not line:
                continue
            if "\t" not in line:
                continue
            m, d = line.split("\t", 1)
            items.append((m, d))
    return items


def prompt_pick(items: list[tuple[str, str]]) -> tuple[str, str]:
    for idx, (_, dem) in enumerate(items, start=1):
        print(f"[{idx:3d}] {dem}")
    while True:
        try:
            choice = input("Select index (q to quit): ").strip()
        except (EOFError, KeyboardInterrupt):
            raise ToolError("Selection aborted (no interactive input available).")
        if choice.lower() in {"q", "quit", "exit"}:
            raise ToolError("Selection aborted by user.")
        if not choice.isdigit():
            print("Please enter a number.")
            continue
        idx = int(choice)
        if 1 <= idx <= len(items):
            return items[idx - 1]
        print("Index out of range.")


def filter_pick(items: list[tuple[str, str]], filt: str) -> tuple[str, str]:
    matches = [(m, d) for m, d in items if filt in d]
    if not matches:
        raise ToolError("No matches for filter. Run llvmir without --filter to choose from the list.")
    if len(matches) == 1:
        return matches[0]

    eprint(f"Multiple matches for filter '{filt}':")
    return prompt_pick(matches)


def extract_asm_block(amdgcn_s: Path, symbol: str, out_path: Path):
    # Grab the whole .text.<symbol> section to include metadata (.amdhsa_kernel, .set vgpr/sgpr, etc.)
    start_pat = re.compile(r"^\s*\.section\s+\.text\." + re.escape(symbol) + r"\b")
    next_section_pat = re.compile(r"^\s*\.section\s+\.text\.")

    keep = False
    found = False
    with amdgcn_s.open("r", encoding="utf-8", errors="ignore") as f_in, out_path.open("w", encoding="utf-8") as f_out:
        for line in f_in:
            if start_pat.search(line):
                keep = True
                found = True
            if keep:
                # Stop when the next .text section begins (and it's not our own header line)
                if found and next_section_pat.search(line) and not start_pat.search(line):
                    break
                f_out.write(line)

    if not found:
        eprint(f"[llvmir] warning: symbol not found in amdgcn.s: {symbol}")


def replace_section(full_s: Path, symbol: str, snippet_s: Path, out_s: Path):
    start_pat = re.compile(r"^\s*\.section\s+\.text\." + re.escape(symbol) + r"\b")
    next_section_pat = re.compile(r"^\s*\.section\s+\.text\.")

    full_lines = full_s.read_text(encoding="utf-8", errors="ignore").splitlines(keepends=True)
    snippet_lines = snippet_s.read_text(encoding="utf-8", errors="ignore").splitlines(keepends=True)

    if not any(start_pat.search(line) for line in snippet_lines):
        raise ToolError("Snippet asm does not contain the expected .text.<symbol> section.")

    start_idx = None
    end_idx = None
    for i, line in enumerate(full_lines):
        if start_pat.search(line):
            start_idx = i
            break
    if start_idx is None:
        raise ToolError("Symbol section not found in full amdgcn.s.")

    for j in range(start_idx + 1, len(full_lines)):
        if next_section_pat.search(full_lines[j]) and not start_pat.search(full_lines[j]):
            end_idx = j
            break
    if end_idx is None:
        end_idx = len(full_lines)

    new_lines = full_lines[:start_idx] + snippet_lines + full_lines[end_idx:]
    out_s.write_text("".join(new_lines), encoding="utf-8")


def extract_metadata_from_readobj(readobj: str, obj_path: Path, symbol: str, out_path: Path):
    proc = subprocess.run(
        [readobj, "--notes", str(obj_path)],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        text=True,
    )
    if proc.returncode != 0:
        eprint(proc.stderr)
        raise ToolError("llvm-readobj failed.")

    lines = proc.stdout.splitlines()
    meta_start = next((i for i, line in enumerate(lines) if "AMDGPU Metadata:" in line), None)
    kernels_line = next((i for i, line in enumerate(lines) if line.strip() == "amdhsa.kernels:"), None)

    header = []
    if meta_start is not None and kernels_line is not None and meta_start <= kernels_line:
        header = lines[meta_start:kernels_line + 1]

    # Parse kernel blocks under amdhsa.kernels
    blocks = []
    current = None
    if kernels_line is not None:
        for line in lines[kernels_line + 1:]:
            if line.startswith("  - .args:"):
                if current:
                    blocks.append(current)
                current = [line]
                continue
            if current is not None:
                # End of metadata block if indentation collapses
                if line.startswith("NoteSection") or line.startswith("}"):
                    break
                current.append(line)
        if current:
            blocks.append(current)

    selected = None
    for block in blocks:
        if any(".name:" in line and symbol in line for line in block):
            selected = block
            break

    if selected is None:
        # Fallback: keep a context window around the first matching line
        match_idx = next((i for i, line in enumerate(lines) if symbol in line), None)
        if match_idx is None:
            selected = lines
        else:
            lo = max(0, match_idx - 30)
            hi = min(len(lines), match_idx + 200)
            selected = lines[lo:hi]
        out_path.write_text("\n".join(selected) + "\n", encoding="utf-8")
        return

    out_path.write_text("\n".join(header + selected) + "\n", encoding="utf-8")


def run_llvmir(cfg: dict, filt: str | None):
    kernel = cfg["kernel"]
    out_base = cfg["out"]

    kernel_dir = out_base / kernel
    dump_dir = pick_latest_dir(kernel_dir)
    if dump_dir is None:
        eprint("[llvmir] no dump found, running dump first")
        dump_dir = run_dump(cfg)

    map_path = dump_dir / "mangled_map.tsv"
    if not map_path.exists():
        eprint("[llvmir] mangled_map.tsv missing, running dump first")
        dump_dir = run_dump(cfg)
        map_path = dump_dir / "mangled_map.tsv"

    items = load_map(map_path)
    if not items:
        raise ToolError("mangled_map.tsv is empty.")

    if filt:
        mangled, demangled = filter_pick(items, filt)
    else:
        mangled, demangled = prompt_pick(items)

    eprint(f"[llvmir] selected: {demangled}")

    # Prepare llvmir output folder
    llvmir_root = dump_dir / "llvmir"
    llvmir_root.mkdir(parents=True, exist_ok=True)
    sym_dir = llvmir_root / safe_name(demangled)
    sym_dir.mkdir(parents=True, exist_ok=True)

    # Re-run compile with IR dump
    tu_rel = SUPPORTED_KERNELS[kernel]
    cc_path = find_compile_commands(cfg["llamacpp"], cfg.get("build_dir"))
    entry = load_compile_command(cc_path, tu_rel)
    cmd_tools = clang_tools_from_command(shlex.split(entry["command"]))

    out_obj = sym_dir / "mmvq.cu.o"
    extra = ["--save-temps=obj", "-mllvm", "-print-after-all", "-mllvm", f"-filter-print-funcs={mangled}"]
    cmd, workdir = build_command(entry, out_obj, extra)

    log_path = sym_dir / "llvmir.log"
    eprint(f"[llvmir] writing log: {log_path}")

    with log_path.open("w", encoding="utf-8") as log:
        proc = subprocess.run(cmd, cwd=workdir, stdout=log, stderr=log)

    if proc.returncode != 0:
        raise ToolError("Compilation failed during llvmir.")

    # Extract asm block for chosen symbol
    amdgcn_s = dump_dir / "amdgcn.s"
    if amdgcn_s.exists():
        asm_out = sym_dir / "asm.s"
        extract_asm_block(amdgcn_s, mangled, asm_out)

    device_out = find_device_out(sym_dir)
    if device_out:
        metadata_out = sym_dir / "metadata.txt"
        extract_metadata_from_readobj(cmd_tools["llvm_readobj"], device_out, mangled, metadata_out)
    else:
        eprint("[llvmir] warning: device .out not found; metadata.txt not generated")

    clean_dir(sym_dir, keep_files={"llvmir.log", "asm.s", "metadata.txt"})


def run_patch(cfg: dict, filt: str | None):
    kernel = cfg["kernel"]
    out_base = cfg["out"]

    kernel_dir = out_base / kernel
    dump_dir = pick_latest_dir(kernel_dir)
    if dump_dir is None or not (dump_dir / "amdgcn.s").exists():
        raise ToolError("Base amdgcn.s not found. Run `llama-kernel dump` first.")

    map_path = dump_dir / "mangled_map.tsv"
    if not map_path.exists():
        raise ToolError("mangled_map.tsv not found. Run `llama-kernel dump` first.")

    items = load_map(map_path)
    if not items:
        raise ToolError("mangled_map.tsv is empty.")

    if filt:
        mangled, demangled = filter_pick(items, filt)
    else:
        mangled, demangled = prompt_pick(items)

    eprint(f"[patch] selected: {demangled}")

    # Locate snippet asm
    sym_dir = dump_dir / "llvmir" / safe_name(demangled)
    snippet_path = sym_dir / "asm.s"
    if not snippet_path.exists():
        raise ToolError(f"Missing asm.s for symbol. Run llvmir first: {sym_dir}")

    modified_dir = dump_dir / "modified"
    if modified_dir.exists():
        shutil.rmtree(modified_dir)
    modified_dir.mkdir(parents=True, exist_ok=True)

    full_s = dump_dir / "amdgcn.s"
    combined_s = modified_dir / "amdgcn.s"
    replace_section(full_s, mangled, snippet_path, combined_s)

    # Build code object from modified assembly
    tu_rel = SUPPORTED_KERNELS[kernel]
    cc_path = find_compile_commands(cfg["llamacpp"], cfg.get("build_dir"))
    entry = load_compile_command(cc_path, tu_rel)
    cmd_tools = clang_tools_from_command(shlex.split(entry["command"]))
    cmd = shlex.split(entry["command"])
    arch = parse_offload_arch(cmd)

    device_o = modified_dir / "kernel.device.o"
    device_hsaco = modified_dir / "kernel.device.hsaco"

    proc = subprocess.run(
        [cmd_tools["llvm_mc"], "-triple=amdgcn-amd-amdhsa", f"-mcpu={arch}", "-filetype=obj",
         str(combined_s), "-o", str(device_o)]
    )
    if proc.returncode != 0:
        raise ToolError("llvm-mc failed.")

    proc = subprocess.run([cmd_tools["ld_lld"], "-shared", "-o", str(device_hsaco), str(device_o)])
    if proc.returncode != 0:
        raise ToolError("ld.lld failed.")

    # Extract and re-bundle hip fatbin
    obj_path = find_output_object(entry, cc_path)
    hip_fatbin = modified_dir / "hip_fatbin.bin"
    proc = subprocess.run(
        [cmd_tools["llvm_objcopy"], f"--dump-section", f".hip_fatbin={hip_fatbin}", str(obj_path)]
    )
    if proc.returncode != 0:
        raise ToolError("Failed to dump .hip_fatbin section from mmvq.cu.o.")

    host_o = modified_dir / "hip_fatbin.host.o"
    device_o_orig = modified_dir / "hip_fatbin.device.o"
    targets = f"hipv4-amdgcn-amd-amdhsa--{arch},host-x86_64-unknown-linux-gnu-"

    proc = subprocess.run(
        [cmd_tools["clang_offload_bundler"],
         "--type=o", "--unbundle",
         "--input", str(hip_fatbin),
         "--output", str(device_o_orig),
         "--output", str(host_o),
         "--targets", targets]
    )
    if proc.returncode != 0:
        raise ToolError("clang-offload-bundler unbundle failed.")

    hip_fatbin_new = modified_dir / "hip_fatbin.new"
    proc = subprocess.run(
        [cmd_tools["clang_offload_bundler"],
         "--type=o",
         "--input", str(device_hsaco),
         "--input", str(host_o),
         "--output", str(hip_fatbin_new),
         "--targets", targets]
    )
    if proc.returncode != 0:
        raise ToolError("clang-offload-bundler bundle failed.")

    # Apply patch to the real object file (backup first)
    backup_path = obj_path.with_suffix(obj_path.suffix + ".bak")
    if not backup_path.exists():
        shutil.copy2(obj_path, backup_path)
        eprint(f"[patch] backed up: {backup_path}")

    proc = subprocess.run(
        [cmd_tools["llvm_objcopy"], f"--update-section", f".hip_fatbin={hip_fatbin_new}", str(obj_path)]
    )
    if proc.returncode != 0:
        raise ToolError("Failed to update .hip_fatbin section in mmvq.cu.o.")

    eprint(f"[patch] applied to: {obj_path}")
    eprint(f"[patch] modified artifacts in: {modified_dir}")
    eprint(f"[patch] hip_fatbin.new ready: {hip_fatbin_new}")

    # Apply the same patched fatbin to the runtime shared library
    build_root = build_root_from_cc(cc_path, cfg)
    so_path = build_root / "bin" / "libggml-hip.so.0"
    if not so_path.exists():
        raise ToolError(f"libggml-hip.so.0 not found: {so_path}")

    so_backup = so_path.with_suffix(so_path.suffix + ".bak")
    if not so_backup.exists():
        shutil.copy2(so_path, so_backup)
        eprint(f"[patch] backed up: {so_backup}")

    proc = subprocess.run(
        [cmd_tools["llvm_objcopy"], f"--update-section", f".hip_fatbin={hip_fatbin_new}", str(so_path)]
    )
    if proc.returncode != 0:
        raise ToolError("Failed to update .hip_fatbin section in libggml-hip.so.0.")

    eprint(f"[patch] applied to: {so_path}")


def run_restore(cfg: dict):
    kernel = cfg["kernel"]
    tu_rel = SUPPORTED_KERNELS[kernel]
    llamacpp = cfg["llamacpp"]

    cc_path = find_compile_commands(llamacpp, cfg.get("build_dir"))
    entry = load_compile_command(cc_path, tu_rel)
    cmd_tools = clang_tools_from_command(shlex.split(entry["command"]))

    obj_path = find_output_object(entry, cc_path)
    backup_path = obj_path.with_suffix(obj_path.suffix + ".bak")

    if backup_path.exists():
        shutil.copy2(backup_path, obj_path)
        eprint(f"[restore] restored from backup: {backup_path}")
    else:
        # Rebuild just mmvq.cu.o using the exact compile command
        cmd = shlex.split(entry["command"])
        workdir = Path(entry["directory"])

        proc = subprocess.run(cmd, cwd=workdir)
        if proc.returncode != 0:
            raise ToolError("Restore rebuild failed.")
        eprint("[restore] rebuilt mmvq.cu.o from compile_commands.json")

    # Restore libggml-hip.so.0 if available, otherwise rebuild ggml-hip
    build_root = build_root_from_cc(cc_path, cfg)
    so_path = build_root / "bin" / "libggml-hip.so.0"
    so_backup = so_path.with_suffix(so_path.suffix + ".bak")
    if so_backup.exists():
        shutil.copy2(so_backup, so_path)
        eprint(f"[restore] restored from backup: {so_backup}")
        return

    if not build_root.exists():
        raise ToolError(f"Build directory not found for ggml-hip rebuild: {build_root}")

    proc = subprocess.run(["cmake", "--build", str(build_root), "--target", "ggml-hip", "--clean-first"])
    if proc.returncode != 0:
        raise ToolError("Restore rebuild of ggml-hip failed.")
    eprint("[restore] rebuilt ggml-hip")


def main():
    parser = argparse.ArgumentParser(description="llama-kernel tool")
    sub = parser.add_subparsers(dest="cmd", required=True)

    sub.add_parser("dump", help="dump amdgcn.s, device.bc, and mangled map")
    p_ir = sub.add_parser("llvmir", help="dump LLVM IR for a selected symbol")
    p_ir.add_argument("--filter", dest="filter", default=None, help="demangled substring to select symbol")
    p_patch = sub.add_parser("patch", help="build modified code object and apply to mmvq.cu.o")
    p_patch.add_argument("--filter", dest="filter", default=None, help="demangled substring to select symbol")
    sub.add_parser("restore", help="restore mmvq.cu.o from backup or rebuild it")

    args = parser.parse_args()

    cfg = resolve_paths(load_config())

    try:
        if args.cmd == "dump":
            run_dump(cfg)
        elif args.cmd == "llvmir":
            run_llvmir(cfg, args.filter)
        elif args.cmd == "patch":
            run_patch(cfg, args.filter)
        elif args.cmd == "restore":
            run_restore(cfg)
        else:
            raise ToolError(f"Unknown command: {args.cmd}")
    except ToolError as e:
        eprint(f"error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
